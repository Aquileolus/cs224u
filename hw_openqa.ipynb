{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf85bea0-68bf-4405-96ec-37579b2e9587",
   "metadata": {},
   "source": [
    "# Homework and bakeoff: Few-shot OpenQA with DSPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a28e9bf5-7956-4c63-9129-7f2cbc468075",
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = \"Christopher Potts and Omar Khattab\"\n",
    "__version__ = \"CS224u, Stanford, Fall 2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b5d964-a45c-496a-bb46-8f31d7b2d591",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cgpotts/cs224u/blob/master/hw_openqa.ipynb)\n",
    "\n",
    "If Colab is opened with this badge, please **save a copy to drive** (from the File menu) before running the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8570fc5-2ac0-4c0e-b350-71990937ebd8",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4da2d82-8c54-4d41-a59d-891f83f85f6e",
   "metadata": {},
   "source": [
    "The goal of this homework is to explore retrieval-augmented in-context learning. This is an exciting area that brings together a number of recent task ideas and modeling innovations. We will use the [DSPy programming library](http://dspy.ai) to build systems in this new mode.\n",
    "\n",
    "Our core task is __open-domain question answering (OpenQA)__. In this task, all that is given by the dataset is a question text, and the task is to answer that question. By contrast, in many modern QA tasks, the dataset provides a text and a gold passage, usually with a firm guarantee that the answer will be a substring of the passage.\n",
    "\n",
    "OpenQA is substantially harder than standard QA. The usual strategy is to use a _retriever_ to find passages in a large collection of texts and train a _reader_ to find answers in those passages. This means we have no guarantee that the retrieved passage will contain the answer we need. If we don't retrieve a passage containing the answer, our reader has no hope of succeeding. Although this is challenging, it is much more realistic and widely applicable than standard QA. After all, with the right retriever, an OpenQA system could be deployed over the entire Web.\n",
    "\n",
    "The task posed by this homework is harder even than OpenQA. We are calling this task __few-shot OpenQA__. The defining feature of this task is that the reader is simply a frozen, general purpose language model. It accepts string inputs (prompts) and produces text in response. It is not trained to answer questions per se, and nothing about its structure ensures that it will respond with a substring of the prompt corresponding to anything like an answer.\n",
    "\n",
    "__Few-shot QA__ (but not OpenQA!) is explored in the famous GPT-3 paper ([Brown et al. 2020](https://arxiv.org/abs/2005.14165)). The authors are able to get traction on the problem using GPT-3, an incredible finding. Our task here – __few-shot OpenQA__ – pushes this even further by retrieving passages to use in the prompt rather than assuming that the gold passage can be used in the prompt. If we can make this work, then it should be a major step towards flexibly and easily deploying QA technologies in new domains.\n",
    "\n",
    "In summary:\n",
    "\n",
    "| Task             | Passage given | Task-specific reader training |Task-specific retriever training  | \n",
    "|-----------------:|:-------------:|:-----------------------------:|:--------------------------------:|\n",
    "| QA               | yes           | yes                           | n/a                              |\n",
    "| OpenQA           | no            | yes                           | maybe                            |\n",
    "| Few-shot QA      | yes           | no                            | n/a                              |\n",
    "| Few-shot OpenQA  | no            | no                            | maybe                            | \n",
    "\n",
    "Just to repeat: your mission is to explore the final line in this table. The core notebook and assignment don't address the issue of training the retriever in a task-specific way, but this is something you could pursue for a final project; [the ColBERT codebase](https://github.com/stanford-futuredata/ColBERT) makes easy.\n",
    "\n",
    "It is a requirement of the bake-off that a general-purpose language model be used. In particular, trained QA systems cannot be used at all, and no fine-tuning is allowed either. See the original system question at the bottom of this message for guidance on which models are allowed.\n",
    "\n",
    "Note: the models we are working with here are _big_. This poses a challenge that is increasingly common in NLP: you have to pay one way or another. You can pay to use the GPT-3 API, or you can pay to use a local model on a heavy-duty cluster computer, or you can pay with time by using a local model on a more modest computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd32bb4-067f-4cd6-943f-3e5574400beb",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149bcb0f-bc76-4277-a359-742d6dcee063",
   "metadata": {},
   "source": [
    "We have sought to make this notebook self-contained and easy to use on a personal computer, on Google Colab, and in Sagemaker Studio. For personal computer use, we assume you have already done everything in [setup.ipynb](setup.ipynb]). For cloud usage, the next few code blocks should handle all set-up steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b983bb-a20a-4c2a-9eee-9c553dd8c070",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import datasets\n",
    "    root_path = '.'\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/cgpotts/cs224u/\n",
    "    !pip install -r cs224u/requirements.txt\n",
    "    root_path = 'dspy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1afb7791-92a3-474d-8c2f-807dc2441413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import dspy\n",
    "import warnings\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2651d-9868-45bf-81df-afafa832896a",
   "metadata": {},
   "source": [
    "### OpenAI set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04cb488-cd40-4f9d-b884-8ff83b012042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c9da704b-d27b-480a-93b5-e16cf7c51803",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '/Users/mingbosha/Documents'\n",
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "\n",
    "\n",
    "# keep the API keys in a `.env` file in the local root directory\n",
    "load_dotenv()\n",
    "\n",
    "openai_key = os.getenv('OPENAI_API_KEY')  # use the .env file as it is a good practice to keep keys outside of one's code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4465db5-4572-457e-b053-10f0185536fe",
   "metadata": {},
   "source": [
    "### ColBERT set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63747138-ae9c-4fc6-b508-0ad411fd58ac",
   "metadata": {},
   "source": [
    "#### Pretrained ColBERT parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf06f38-3dd6-4171-8b72-f5703df140d8",
   "metadata": {},
   "source": [
    "For this set-up phase, we first download pretrained ColBERT parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4925831c-f4d2-4b6b-87ed-145125c8f668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-17 17:08:59--  https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "connected. to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... \n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 405924985 (387M) [application/octet-stream]\n",
      "Saving to: ‘data/openqa/colbertv2.0.tar.gz’\n",
      "\n",
      "colbertv2.0.tar.gz  100%[===================>] 387.12M  2.07MB/s    in 80s     \n",
      "\n",
      "2025-03-17 17:10:19 (4.82 MB/s) - ‘data/openqa/colbertv2.0.tar.gz’ saved [405924985/405924985]\n",
      "\n",
      "x colbertv2.0/\n",
      "x colbertv2.0/artifact.metadata\n",
      "x colbertv2.0/vocab.txt\n",
      "x colbertv2.0/tokenizer.json\n",
      "x colbertv2.0/special_tokens_map.json\n",
      "x colbertv2.0/tokenizer_config.json\n",
      "x colbertv2.0/config.json\n",
      "x colbertv2.0/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"colbertv2.0.tar.gz\")):\n",
    "    !mkdir -p data/openqa\n",
    "    # ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
    "    !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P data/openqa/\n",
    "    !tar -xvzf data/openqa/colbertv2.0.tar.gz -C data/openqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a89bd6c-5497-4808-b2cf-9e15d9c37104",
   "metadata": {},
   "source": [
    "If something went wrong with the above, you can just download the file https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz, unarchive it, and move the resulting `colbertv2.0` directory into the `data/openqa` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf501ee-290b-4007-b04d-c175c3124806",
   "metadata": {},
   "source": [
    "#### Prebuilt ColBERT index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e330d4c-3d9f-4182-9c40-37010a5e5afd",
   "metadata": {},
   "source": [
    "Then we download a prebuilt index that covers the domain of our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d4bc73b-6936-44e2-bc80-7aca800abd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_home = os.path.join(\"experiments\", \"notebook\", \"indexes\", \"cs224u.collection.2bits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d8dd51-d0d9-4d72-ae77-f00f6151889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-17 17:12:12--  https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz\n",
      "Resolving web.stanford.edu (web.stanford.edu)... 171.67.215.200\n",
      "connected. to web.stanford.edu (web.stanford.edu)|171.67.215.200|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 600150346 (572M) [application/x-gzip]\n",
      "Saving to: ‘experiments/notebook/indexes/cs224u.collection.2bits.tgz’\n",
      "\n",
      "cs224u.collection.2 100%[===================>] 572.35M   599KB/s    in 19m 58s \n",
      "\n",
      "2025-03-17 17:32:10 (489 KB/s) - ‘experiments/notebook/indexes/cs224u.collection.2bits.tgz’ saved [600150346/600150346]\n",
      "\n",
      "x cs224u.collection.2bits/\n",
      "x cs224u.collection.2bits/buckets.pt\n",
      "x cs224u.collection.2bits/avg_residual.pt\n",
      "x cs224u.collection.2bits/3.codes.pt\n",
      "x cs224u.collection.2bits/4.codes.pt\n",
      "x cs224u.collection.2bits/4.residuals.pt\n",
      "x cs224u.collection.2bits/metadata.json\n",
      "x cs224u.collection.2bits/doclens.4.json\n",
      "x cs224u.collection.2bits/ivf.pt\n",
      "x cs224u.collection.2bits/3.metadata.json\n",
      "x cs224u.collection.2bits/1.codes.pt\n",
      "x cs224u.collection.2bits/5.metadata.json\n",
      "x cs224u.collection.2bits/5.codes.pt\n",
      "x cs224u.collection.2bits/0.metadata.json\n",
      "x cs224u.collection.2bits/doclens.3.json\n",
      "x cs224u.collection.2bits/doclens.1.json\n",
      "x cs224u.collection.2bits/0.residuals.pt\n",
      "x cs224u.collection.2bits/doclens.0.json\n",
      "x cs224u.collection.2bits/4.metadata.json\n",
      "x cs224u.collection.2bits/doclens.5.json\n",
      "x cs224u.collection.2bits/1.residuals.pt\n",
      "x cs224u.collection.2bits/plan.json\n",
      "x cs224u.collection.2bits/centroids.pt\n",
      "x cs224u.collection.2bits/doclens.2.json\n",
      "x cs224u.collection.2bits/2.residuals.pt\n",
      "x cs224u.collection.2bits/3.residuals.pt\n",
      "x cs224u.collection.2bits/0.codes.pt\n",
      "x cs224u.collection.2bits/1.metadata.json\n",
      "x cs224u.collection.2bits/5.residuals.pt\n",
      "x cs224u.collection.2bits/2.codes.pt\n",
      "x cs224u.collection.2bits/cs224u.collection.tsv\n",
      "x cs224u.collection.2bits/2.metadata.json\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(index_home):\n",
    "    !wget https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz -P experiments/notebook/indexes\n",
    "    !tar -xvzf experiments/notebook/indexes/cs224u.collection.2bits.tgz -C experiments/notebook/indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2443e3-efe6-444d-98bd-63fa2634d8ff",
   "metadata": {},
   "source": [
    "If something went wrong with the above, download the file https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz, unarchive it, and move the resulting `cs224u.collection.2bits` directory into the `experiments/notebook/indexes` directory (which you will probably need to create)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd3e9ff-c3d4-4a02-acfa-0d9183bce133",
   "metadata": {},
   "source": [
    "#### ColBERT server"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fde4ad-a0e2-49a2-b3ec-446c5cb95a95",
   "metadata": {},
   "source": [
    "The final step for ColBERT is to create a local retriever for use with DSPy. The preferred method for doing this is with a seperate server. \n",
    "\n",
    "__Local usage__: If you are working with this notebook locally and a having a CUDA based device, make sure you have the [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads) installed to be able to serve it on GPU. Otherwise you would need to run it on CPU. The next steps are for GPU usage. \n",
    "Open a new terminal window, navigate to the same directory as this notebook, and enter the following code:\n",
    "\n",
    "```\n",
    "conda activate nlu\n",
    "git clone https://github.com/stanford-futuredata/ColBERT/ ;\n",
    "export INDEX_ROOT=experiments/notebook/indexes/cs224u.collection.2bits/ ;\n",
    "export INDEX_HOME=cs224u.collection.2bits ;\n",
    "export PORT=8888 ;\n",
    "python ColBERT/server.py \n",
    "```\n",
    "\n",
    "This will start the server and you should be all set.\n",
    "\n",
    "__Colab usage__: If you are working in a Colab _and you have a Pro account_, you can open a terminal from the lower left corner of the interface and then paste in the above code. If you don't have a Pro account, then it should work to uncomment the code in the following cell and run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2542a5-610f-4e77-9f00-ec86b18e1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"INDEX_ROOT\"] = \"experiments/notebook/indexes/cs224u.collection.2bits/\"\n",
    "#os.environ[\"INDEX_HOME\"] = \"cs224u.collection.2bits\"\n",
    "#os.environ[\"PORT\"] = \"8888\"\n",
    "\n",
    "#!git clone https://github.com/stanford-futuredata/ColBERT/\n",
    "\n",
    "#!nohup python ColBERT/server.py &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56ea89-7055-401f-8afc-8e7687da284b",
   "metadata": {},
   "source": [
    "This will take a minute to get started, and you won't get feedback on its progress, unfortunately. You can check that a server is running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07cae52-81d9-4ff4-9a3b-cf79cf2d74a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ps aux | grep server.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988243e-6985-4ccd-a40e-9a2475566ed3",
   "metadata": {},
   "source": [
    "You should see a mention of `ColBERT/server.py` in the output. \n",
    "\n",
    "Assuming the server is now running, we can connect to it:\n",
    "\n",
    "*Note*: if the ColBERT server is running on a separate server, you can update `127.0.0.1` with the server's IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "556f268f-1a71-476d-bb13-8093feadaf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = dspy.ColBERTv2(url=\"http://10.0.0.38:8889//api/search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "84953cae-12eb-4de0-ac4c-d92121cd285e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'long_text': 'This is basically just a shade of white, which itself is a very popular, common, and (whisper it) ordinary smartphone color. So this is likely to sell well and unlikely to turn heads, but fitting in is sometimes desirable. ... Finally, there’s a Black Titanium shade, which has a hint of gray to it but is by far the darkest shade that you can get the iPhone 16 Pro and iPhone 16 Pro Max in.'}\n",
      "{'long_text': \"Natural Titanium is pleasant but a but basic, and arguably lacks the punch Apple's classic Space Gray color offers. White Titanium really caught our eye, which when combined with the black of the rear cameras, give the iPhone 16 Pro and 16 Pro Max a Star Wars Stormtrooper look, which we rather like and therefore recommend the most.\"}\n",
      "{'long_text': 'The iPhone 16 Pro and iPhone 16 Pro Max excel in numerous ways, from powerful chipsets to capable cameras and beyond, but do their colors impress? Typically, Apple just offers a small number of color choices for its Pro phones, and these are usually quite smart and understated.'}\n",
      "{'long_text': \"For the most part, this trend has continued for the iPhone 16 Pro and Pro Max, with four shades offered, none of which come close to the brightness of some iPhone 16 colors. ... Below, you'll find images and details of all four Pro color options, and note that all four choices are offered on both the iPhone 16 Pro and the iPhone 16 Pro Max.\"}\n",
      "{'long_text': \"Faster processor, clear crisp screen and so many features. ... Eddie . 3 days ago · Yes, I'd recommend this product. Everything is going well. ... Janiffer . 4 days ago · Yes, I'd recommend this product. Love that the charger port is the same now as Galaxy phones and iPad Pro now and all the new features the 16 has ... Kris Pereira . 4 days ago · Yes, I'd recommend this product. I recently upgraded to the iPhone 16 Pro Max. When setting up my new phone there was an issue with the old sim and the new eSIM.\"}\n",
      "{'long_text': 'The displays have rounded corners. When measured as a rectangle, the screen is 6.12 inches (iPhone 16), 6.69 inches (iPhone 16 Plus), 6.27 inches (iPhone 16 Pro) or 6.86 inches (iPhone Pro Max) diagonally. Actual viewable area is less.'}\n",
      "{'long_text': 'To transfer content to a new iPhone 16 Pro Max, you can use the \"Transfer or Reset iPhone\" page in Settings. You can also restore from an iCloud backup. -Harry ... Taysia Leget . Feb 26, 2025 ... You can find out more at the link below regarding starting service with Verizon. -Dee https://www.verizon.com/solutions-and-services/credit-check/ ... They will transfer from another Apple or Android phone, yes. Details are available on our Content Transfer page here -Josh'}\n",
      "{'long_text': 'iPhone 16 Pro Max delivers an incredibly power-efficient performance with up to 33 hours video playback.3 Charge via USB-C or snap on a MagSafe charger for faster wireless charging.4 · With iOS 18 you can tint your Home Screen icons with any color. Find your favorite shots faster in the redesigned Photos app.'}\n",
      "{'long_text': 'Up to 33 hours video playback on iPhone 16 Pro Max8 ... Personalize your Home Screen. Tint your icons with any color. Rearrange and resize apps and widgets.'}\n",
      "{'long_text': '6.3” iPhone 16 Pro3 in four colors 6.9” iPhone 16 Pro Max3 & 6.3” iPhone 16 Pro3 in Desert Titanium 6.9” iPhone 16 Pro Max3 & 6.3” iPhone 16 Pro3 in Black Titanium 6.9” iPhone 16 Pro Max3 & 6.3” iPhone 16 Pro3 in White Titanium 6.9” iPhone 16 Pro Max3 & 6.3” iPhone 16 Pro3 in Natural Titanium'}\n",
      "{'long_text': 'Just point your iPhone 16 Pro to discover more or interact with something in front of you. Pull up a review of a restaurant you pass, search for where to buy a new item you spotted, and more. Camera Control is a picture of innovation. On the surface, a sapphire crystal with a smooth texture is surrounded by a color-matched fine stainless steel trim.'}\n",
      "{'long_text': 'The “Dancing in the Flames” cinematographer Erik Henriksson films the video in dreamlike slow motion using 4K 120 fps Dolby Vision on iPhone 16 Pro. Thanks to Camera Control, he could make technical decisions by simply sliding a finger to adjust camera functions like exposure or focal length — all without missing a beat. The new 48MP Fusion camera has a faster sensor and a new architecture called Apple Camera Interface, which moves data from the sensor to the chip more efficiently. This allows frame-by-frame, cinema-quality color grading for 4K 120 fps Dolby Vision with the new image signal processor in the A18 Pro chip.'}\n",
      "{'long_text': 'As usual, the base iPhone 16 and iPhone 16 Plus models are available in brighter and more colorful options than the iPhone 16 Pro and iPhone 16 Pro Max, which come in more conservative colors that invoke a more luxurious look.'}\n",
      "{'long_text': 'The iPhone 16 in White, a new color. Apple/Business Insider ... The iPhone 16 Pro and iPhone 16 Pro Max are available in four colors: Desert Titanium, Natural Titanium, Black Titanium, and White Titanium. Their titanium frames and rear glass panels have a frosted matte texture.'}\n",
      "{'long_text': \"The rear camera units are clear glass with an identical color shade as the rear glass panel, except for the Black Titanium model's camera unit, which appears deeper than the rest of the phone's black color. The titanium frames have a slightly darker shade than the rest of the phones. Read our full iPhone 16 Pro and iPhone 16 Pro Max review to learn about their performance, cameras, battery life, and more.\"}\n",
      "{'long_text': 'The White Titanium option for the iPhone 16 Pro models is the most uniform in color (the Pro Max model pictured).'}\n",
      "{'long_text': \"The iPhone 16 also comes with a new color-infused backglass that has allowed Apple to get some gorgeous, saturated, and rich colors like Ultramarine, Teal, and Pink. On the other hand, the iPhone 16 Pro and Pro Max continue Apple's tradition of a more conservative color approach for the pro-oriented people.\"}\n",
      "{'long_text': 'Black color is almost identical on the iPhone 16 and iPhone 15 | Image Credit - Apple ... The iPhone 16 Pro and Pro Max maintain a professional and sleek aesthetic, with subtle and refined color options. The Pro models this year continue to follow the Titanium-inspired theme, but this time, they feature a grade 5 titanium.'}\n",
      "{'long_text': 'You get to enjoy a gorgeous looking microblasted texture for a premium and unique look on all four colors that the iPhone 16 Pro and Pro Max are available in.'}\n",
      "{'long_text': \"The new grade 5 titanium ensures deeper colors on the backs of the new iPhones. See how they compare to the models from last year. The iPhone 16 Pro in Black Titanium sports a darker black than its predecessor. | Image Credit - Apple · Natural Titanium on the iPhone 16 Pro is lighter and cleaner-looking than the 15 Pro's. | Image Credit - Apple · White Titanium is now brighter and sports colder undertones than the warmer White Titanium on the 15 Pro. | Image Credit - Apple · There's no Blue Titanium this year, we have the gorgeous Desert Titanium on the iPhone 16 Pro.\"}\n"
     ]
    }
   ],
   "source": [
    "from dspy.retrieve.you_rm import YouRM\n",
    "import os\n",
    "\n",
    "you_rm = YouRM(endpoint=\"search\", safesearch=\"strict\")\n",
    "\n",
    "results = you_rm(\"how many colors are there for iPhone 16 Pro Max?\", k=5)\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9bbc99-fcb2-4b22-b09b-c35371611709",
   "metadata": {},
   "source": [
    "### DSPy set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562fc500-bbab-48b7-a704-67c6d57bb09b",
   "metadata": {},
   "source": [
    "Here we establish the Language Model `lm` and Retriever Model `rm` that we will be using. The defaults for `lm` are just for development. You may want to develop using an inexpensive model and then do your final evalautions wih an expensive one. DSPy has support for a wide range of model APIs and local models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c118b014-e13f-433d-ad60-074636c7e738",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
    "\n",
    "dspy.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711785d7-6bb9-4041-92e6-cc5f9308477e",
   "metadata": {},
   "source": [
    "Here's a command you can run to see which OpenAI models are available; OpenAI has entered into an increasingly closed mode where many older models are not available, so there are likely to be some surprises lurking here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a859fbb-e985-4031-b8ed-34f3b034db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(api_key = openai_key)\n",
    "# models = client.models.list()\n",
    "# print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b3dc2-87d7-4b8b-b603-ee567e008710",
   "metadata": {},
   "source": [
    "## SQuAD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de295d35-fea5-46d2-9a01-022ad88e54cd",
   "metadata": {},
   "source": [
    "Our core development dataset is [SQuAD](https://rajpurkar.github.io/SQuAD-explorer/). We chose this dataset because it is well-known and widely used, and it is large enough to support lots of meaningful development work, without, though, being so large as to require lots of compute power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5eaf2fd0-d060-4100-8702-f7311efd6129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b95414da984e3987836423b5f495bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ed764695b49f0bb04bb05c416ec32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee45bc35c7f24351b02257bd3635118e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef078abac7ff43588f0b42dc9d5048d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e965425e7543788376b9c0b06fb75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "squad = load_dataset(\"squad\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36965402-e3da-4531-b7e9-4b12cebcdf30",
   "metadata": {},
   "source": [
    "The following utility just reads a SQuAD split in as a list of `dspy.Example` instances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21ad3e0b-7662-43b8-9409-a1a57442458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_squad_split(squad, split=\"validation\"):\n",
    "    \"\"\"\n",
    "    Use `split='train'` for the train split.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dspy.Example with attributes question, answer\n",
    "\n",
    "    \"\"\"\n",
    "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
    "    exs = [dspy.Example(question=q, answer=a['text'][0]).with_inputs(\"question\")\n",
    "           for eid, title, context, q, a in data]\n",
    "    return exs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3847d38-4e70-46b7-bf46-4c8b784c5ee5",
   "metadata": {},
   "source": [
    "### SQuAD train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051c91e1-586b-4747-be39-3092e60f182f",
   "metadata": {},
   "source": [
    "To build few-shot prompts, we will often sample SQuAD train examples, so we load that split here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66c4feba-d580-4984-a449-0b92a53ef13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_train = get_squad_split(squad, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ab8c41-8eae-4d15-ad4d-e28b3c58eb4a",
   "metadata": {},
   "source": [
    "### SQuAD dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37198b33-c47b-4e0e-af8b-c00860658cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_dev = get_squad_split(squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c40c768-57cc-4a07-a3ef-5e34262b0ace",
   "metadata": {},
   "source": [
    "### SQuAD dev sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636601b5-c7ad-4177-a6d6-f3afdb0bedae",
   "metadata": {},
   "source": [
    "Evaluations are expensive in this new era! Here's a small sample to use for dev assessments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64ccdd0e-de78-440d-bfbe-358c12eada5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "dev_exs = random.sample(squad_dev, k=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28265d01-890d-4f04-b518-da0e8a1cb235",
   "metadata": {},
   "source": [
    "## DSPy basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101b9d12-fc8c-4aae-b09e-0d72a4aa54f5",
   "metadata": {},
   "source": [
    "### LM usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c278daac-11f9-4327-a06f-1c408a06a71d",
   "metadata": {},
   "source": [
    "Here's the most basic way to use the LM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "02364ed6-3c6d-4eaf-849a-2d9e30d84b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The birthplace of the first author to win a Hugo Award for a translation is Japan. The author is Yoshio Kobayashi, who won the Hugo Award for Best Novel in 1980 for his translation of \"The Left Hand of Darkness\" by Ursula K. Le Guin.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2356d9a8-750b-4383-bc5b-4173ca5c13ac",
   "metadata": {},
   "source": [
    "Keyword arguments to the underlying LM are passed through:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ab8deb-3b9d-4f57-bd70-7c170be294c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['There are two states that do not border any other U.S. state: Alaska and Hawaii.',\n",
       " 'There are five U.S. states that do not border any other U.S. states. They are:\\n\\n1. Alaska\\n2. Hawaii\\n3. Washington D.C.\\n4. Delaware\\n5. Rhode Island',\n",
       " 'Maine and Hawaii are the only two U.S. states that do not share a border with any other U.S. state.',\n",
       " 'There are three U.S. states that do not share a border with any other U.S. states: Alaska, Hawaii, and Rhode Island.']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm(\"Which U.S. states border no U.S. states?\", temperature=0.9, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e8d99-6d49-420d-ab5d-cc01b53cd4a1",
   "metadata": {},
   "source": [
    "With `lm.inspect_history`, we can see the most recent language model calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f7cb5a5-3a3f-4e78-b9af-488fadc896ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Which U.S. states border no U.S. states?\u001b[32m There are two states that do not border any other U.S. state: Alaska and Hawaii.\u001b[0m\u001b[31m \t (and 3 other completions)\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a0f2df-df1f-422d-bff3-6c4a3d947f6e",
   "metadata": {},
   "source": [
    "### Signature-based prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0888a2a-fcaa-44b0-beef-b097c856c74b",
   "metadata": {},
   "source": [
    "In DSPy, __signatures__ are declarative statements about what we want the model to do. In the following `\"question -> answer\"` is the signature (the most basic QA signature one could write), and `dspy.Predict` is used to turn this into a complete QA system: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11f04cba-7d46-4680-a154-a0062243618e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_predictor = dspy.Predict(\"question -> answer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a994fc10-8c28-4836-bd7c-008a9a3d34e4",
   "metadata": {},
   "source": [
    "Here we use `basic_predictor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfe102d0-c0e5-45ad-aae8-51f6ea6e70f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Paris, France'\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_predictor(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ad1a1b-d422-46df-8b03-4054bfec5fc1",
   "metadata": {},
   "source": [
    "And here is the prompt that was given to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af4f86db-97d5-4742-8468-4627de12f181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Given the fields `question`, produce the fields `answer`.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: ${answer}\n",
      "\n",
      "---\n",
      "\n",
      "Question: What is the birthplace of the first author to win a Hugo Award for a translation?\n",
      "Answer:\u001b[32m Paris, France\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7845f62b-8af3-4fa2-af8d-f4ddd1181f30",
   "metadata": {},
   "source": [
    "In many cases, we will want more control over the prompt. Writing a small custom `dspy.Signature` class is the easiest way to accomplish this. In the following, we just just tweak the initial instruction and provide some formatting guidance for the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9dda770-e7ca-4682-b283-d4f4525adb68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83f7297a-b174-4566-8748-6b66d515ed25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sig_predictor = dspy.Predict(BasicQASignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30a02d55-fac7-43c3-851b-3e21f06df14d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Maine, Hawaii'\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_predictor(question=\"Which U.S. states border no U.S. states?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2f613c05-ec78-4129-ac44-71bac4e253ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: Which U.S. states border no U.S. states?\n",
      "Answer:\u001b[32m Maine, Hawaii\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56169f83-0df6-46dc-b617-fadff1b96132",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244aed0-403e-4707-a9eb-e29fc1e4dc57",
   "metadata": {},
   "source": [
    "One of the hallmarks of DSPy is that it adopts design patterns from PyTorch. The main example of this is DSPy's use of the `Module` as the basic unit for writing simple and complex programs. Here is a very basic module for QA that makes use of `BasicQASignature` as we defined it just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "506c9946-fee4-4dc3-a05e-767f85c25292",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.generate_answer(question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c921aaed-6351-443d-8478-6e9a64b49d45",
   "metadata": {},
   "source": [
    "As with PyTorch, the `forward` method is called when we want to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d67f65b7-0fea-40a3-ac78-795926025653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_qa_model = BasicQA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7044ec84-f76a-4af4-93f5-a82579237868",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='Poland'\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9961c89-914a-4736-8a01-1a3cd401821a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The modular design of DSPy starts to become apparent now. If you want to change the above to use chain of thought instead of regular predictions, you need only change `dspy.Predict` to `dspy.ChainOfThought`, and similarly for `dspy.ReAct`, `dspy.ProgramOfThought`, or a module you wrote yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9dac4-9495-448d-ad4b-38ab7260915b",
   "metadata": {},
   "source": [
    "### Optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5200696-808f-4061-878c-26aa20701d58",
   "metadata": {},
   "source": [
    "The QA system we've defined so far is a zero-shot system. To change it into a few-shot system, we will rely on a DSPy optimizer (__teleprompter__). This will allow us to flexibly move between the zero-shot and few-shot formulations. The following code achieves this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fdab9850-1d4d-4e04-b389-6ef55fd0b425",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mingbosha/Documents/cache/compiler\n"
     ]
    }
   ],
   "source": [
    "from dspy.teleprompt import LabeledFewShot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72045705-2f27-46fe-b7bc-801a7d2e9ae4",
   "metadata": {},
   "source": [
    "Here we instantiate a `LabeledFewShot` teleprompter that will add three demonstrations. These will be sampled randomly from the set of train examples we provide:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "befc8c18-fc64-4947-800d-6455dee90b68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fewshot_teleprompter = LabeledFewShot(k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b512d9-ec54-49ca-ab7a-900dc2eea6cc",
   "metadata": {},
   "source": [
    "And then we call `compile` on `basic_qa_model` as we defined it above. This returns a new module that we use like any other in DSPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b327b603-2943-4bcc-b498-1fbafafefd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basic_fewshot_qa_model = fewshot_teleprompter.compile(basic_qa_model, trainset=squad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "921ec7f1-ed44-48a3-9c92-0e22911688f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    answer='China'\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_fewshot_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180cdaa-dd34-4e0d-8455-e394bfde9fcc",
   "metadata": {},
   "source": [
    "With `inspect_history`, we can see that prompts now contain demonstrations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f9507fe6-1cc7-4c0a-8520-cc3812a07c27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What are new responsibilities pharmacy technicians now deal with?\n",
      "Answer: patients' prescriptions and patient safety issues\n",
      "\n",
      "Question: What do capitalist firms substitute equipment for in a Marxian analysis?\n",
      "Answer: labor inputs\n",
      "\n",
      "Question: Which building was the NFL Experience held at for Super Bowl 50?\n",
      "Answer: Moscone Center\n",
      "\n",
      "Question: In South Africa, along with privately governed schools, what schools are classified as independent?\n",
      "Answer: traditional private\n",
      "\n",
      "Question: In 1517 who was Luther's bishop?\n",
      "Answer: Albert of Mainz\n",
      "\n",
      "Question: What would a teacher do for someone who is cocky?\n",
      "Answer: deflate\n",
      "\n",
      "Question: Who continued to hold the citadel of Bukhara after the Mongols took the rest of the city?\n",
      "Answer: a unit of Turkish defenders\n",
      "\n",
      "Question: In what year did the film also mention the number of regenerations?\n",
      "Answer: 1996\n",
      "\n",
      "Context: «Biplane | years after World War II and is still in production, while the WACO Classic YMF is a reproduction of the original Waco design. The vast majority of biplane designs have been fitted with reciprocating engines of comparatively low power; exceptions include the Antonov An-3 and WSK-Mielec M-15 Belphegor, fitted with turboprop and turbofan engines respectively. Some older biplane designs, such as the Grumman Ag Cat and the aforementioned An-2 (in the form of the An-3) are available in upgraded versions with turboprop engines. The two most produced biplane designs are the 1913 British Avro 504 (8,970 built by November 1918)»\n",
      "Question: What kind of engines did the biplane design have?\n",
      "Answer:\u001b[32m reciprocating engines\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What are new responsibilities pharmacy technicians now deal with?\n",
      "Answer: patients' prescriptions and patient safety issues\n",
      "\n",
      "Question: What do capitalist firms substitute equipment for in a Marxian analysis?\n",
      "Answer: labor inputs\n",
      "\n",
      "Question: Which building was the NFL Experience held at for Super Bowl 50?\n",
      "Answer: Moscone Center\n",
      "\n",
      "Question: In South Africa, along with privately governed schools, what schools are classified as independent?\n",
      "Answer: traditional private\n",
      "\n",
      "Question: In 1517 who was Luther's bishop?\n",
      "Answer: Albert of Mainz\n",
      "\n",
      "Question: What would a teacher do for someone who is cocky?\n",
      "Answer: deflate\n",
      "\n",
      "Question: Who continued to hold the citadel of Bukhara after the Mongols took the rest of the city?\n",
      "Answer: a unit of Turkish defenders\n",
      "\n",
      "Question: In what year did the film also mention the number of regenerations?\n",
      "Answer: 1996\n",
      "\n",
      "Context: «University of Chicago | by two University of Chicago trustees and plotted by Chicago architect Henry Ives Cobb. The Main Quadrangles consist of six quadrangles, each surrounded by buildings, bordering one larger quadrangle. The buildings of the Main Quadrangles were designed by Cobb, Shepley, Rutan and Coolidge, Holabird & Roche, and other architectural firms in a mixture of the Victorian Gothic and Collegiate Gothic styles, patterned on the colleges of the University of Oxford. (Mitchell Tower, for example, is modeled after Oxford's Magdalen Tower, and the university Commons, Hutchinson Hall, replicates Christ Church Hall.) After the 1940s, the Gothic style on campus began to»\n",
      "Question: How many quadrangles does the Main Quadrangles have?\n",
      "Answer:\u001b[32m six\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "Question: ${question}\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Question: What are new responsibilities pharmacy technicians now deal with?\n",
      "Answer: patients' prescriptions and patient safety issues\n",
      "\n",
      "Question: What do capitalist firms substitute equipment for in a Marxian analysis?\n",
      "Answer: labor inputs\n",
      "\n",
      "Question: In South Africa, along with privately governed schools, what schools are classified as independent?\n",
      "Answer: traditional private\n",
      "\n",
      "Question: In 1517 who was Luther's bishop?\n",
      "Answer: Albert of Mainz\n",
      "\n",
      "Question: What would a teacher do for someone who is cocky?\n",
      "Answer: deflate\n",
      "\n",
      "Question: Who continued to hold the citadel of Bukhara after the Mongols took the rest of the city?\n",
      "Answer: a unit of Turkish defenders\n",
      "\n",
      "Question: In what year did the film also mention the number of regenerations?\n",
      "Answer: 1996\n",
      "\n",
      "Context: «Super Bowl 50 | towards the game by residents of the city, the statues notably became the target of vandals, with the \"SUPER BOWL 50\" lettering on their bases re-arranged to form other phrases such as \"SUPERB OWL\", \"SUP BRO 50\", and after the Alamo Square statue was toppled, \"OOPS\". The annual NFL Experience was held at the Moscone Center in San Francisco. In addition, \"Super Bowl City\" opened on January 30 at Justin Herman Plaza on The Embarcadero, featuring games and activities that will highlight the Bay Area's technology, culinary creations, and cultural diversity. More than a million people are expected to attend»\n",
      "Question: Which building was the NFL Experience held at for Super Bowl 50?\n",
      "Answer:\u001b[32m Moscone Center\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba48440-4a65-41e8-b397-7b79f65fa0fe",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e8734a-49a1-4093-a2fb-09bb7d2f2859",
   "metadata": {},
   "source": [
    "Our evaluation metric is a standard one for SQuAD and related tasks: exact match of the answer (EM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f052a79f-ad9f-4f3e-a195-809567e2eea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.evaluate import answer_exact_match\n",
    "from dspy.evaluate.evaluate import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7341a846-5158-4acf-8aa5-aca61ef40174",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_exact_match(dspy.Example(answer=\"STAGE 2!\"), dspy.Prediction(answer=\"stage 2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f640e5bf-823f-4cdb-92da-a28f5cea7760",
   "metadata": {},
   "source": [
    "In DSPy, `Evaluate` objects provide a uniform interface for running evaluations. Here are two for us to use in development. The first will evaluate on all of `dev_exs` and should provide a meaningful picture of how a system is doing. It could be expensive to use it a lot, though. The second is for debugging and is probably too small to give a reliable estimate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3b58b-c114-4316-b8d7-2d8049132c1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dev_evaluater = Evaluate(\n",
    "    devset=dev_exs, # 200 examples\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "72fd504e-4684-445d-b0cc-363cd1685b73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tiny_evaluater = Evaluate(\n",
    "    devset=dev_exs[: 15],\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d88a6c-55b6-4994-9413-1a2301c94903",
   "metadata": {},
   "source": [
    "Here is a tiny (debugging-oriented) evaluation of our few-shot QA sytem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4f736065-39f2-4d76-a258-e852767dbb8e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2 / 15  (13.3): 100%|███████████████████████████████| 15/15 [00:05<00:00,  2.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f597d th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f597d td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_f597d_row0_col0, #T_f597d_row0_col1, #T_f597d_row0_col2, #T_f597d_row0_col3, #T_f597d_row1_col0, #T_f597d_row1_col1, #T_f597d_row1_col2, #T_f597d_row1_col3, #T_f597d_row2_col0, #T_f597d_row2_col1, #T_f597d_row2_col2, #T_f597d_row2_col3, #T_f597d_row3_col0, #T_f597d_row3_col1, #T_f597d_row3_col2, #T_f597d_row3_col3, #T_f597d_row4_col0, #T_f597d_row4_col1, #T_f597d_row4_col2, #T_f597d_row4_col3 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f597d\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f597d_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_f597d_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_f597d_level0_col2\" class=\"col_heading level0 col2\" >pred_answer</th>\n",
       "      <th id=\"T_f597d_level0_col3\" class=\"col_heading level0 col3\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f597d_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f597d_row0_col0\" class=\"data row0 col0\" >In 1517 who was Luther's bishop?</td>\n",
       "      <td id=\"T_f597d_row0_col1\" class=\"data row0 col1\" >Albert of Mainz</td>\n",
       "      <td id=\"T_f597d_row0_col2\" class=\"data row0 col2\" >Albert of Mainz</td>\n",
       "      <td id=\"T_f597d_row0_col3\" class=\"data row0 col3\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f597d_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f597d_row1_col0\" class=\"data row1 col0\" >When was the construction that changed the Rhine's Delta?</td>\n",
       "      <td id=\"T_f597d_row1_col1\" class=\"data row1 col1\" >20th Century</td>\n",
       "      <td id=\"T_f597d_row1_col2\" class=\"data row1 col2\" >13th century</td>\n",
       "      <td id=\"T_f597d_row1_col3\" class=\"data row1 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f597d_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f597d_row2_col0\" class=\"data row2 col0\" >How many companies were registered in Warsaw in 2006?</td>\n",
       "      <td id=\"T_f597d_row2_col1\" class=\"data row2 col1\" >304,016</td>\n",
       "      <td id=\"T_f597d_row2_col2\" class=\"data row2 col2\" >over 100,000</td>\n",
       "      <td id=\"T_f597d_row2_col3\" class=\"data row2 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f597d_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f597d_row3_col0\" class=\"data row3 col0\" >What is the CJEU's duty?</td>\n",
       "      <td id=\"T_f597d_row3_col1\" class=\"data row3 col1\" >to \"ensure that in the interpretation and application of the Treaties the law is observed\"</td>\n",
       "      <td id=\"T_f597d_row3_col2\" class=\"data row3 col2\" >interpret EU law</td>\n",
       "      <td id=\"T_f597d_row3_col3\" class=\"data row3 col3\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f597d_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f597d_row4_col0\" class=\"data row4 col0\" >What would a teacher do for someone who is cocky?</td>\n",
       "      <td id=\"T_f597d_row4_col1\" class=\"data row4 col1\" >deflate</td>\n",
       "      <td id=\"T_f597d_row4_col2\" class=\"data row4 col2\" >ignore them</td>\n",
       "      <td id=\"T_f597d_row4_col3\" class=\"data row4 col3\" >False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x33d3791c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 10 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "13.33"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_evaluater(basic_fewshot_qa_model, metric=answer_exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1b41d-760c-4f28-8a2d-7f037b4f9d97",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d4c8f4-a537-4d9b-9500-f881fceef1de",
   "metadata": {},
   "source": [
    "The final major component of our systems is retrieval. When we defined `rm`, we connected to a remote ColBERT index and retriever system that we can now use for search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfd114-96cf-468a-bac3-d3d39d6f3ca6",
   "metadata": {},
   "source": [
    "The basic `dspy.retrieve` method returns only passages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d8f4cafc-f5db-41c0-9561-ecde61331666",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever = dspy.Retrieve(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "891fc391-c177-4da7-9332-ab20cdba3c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = retriever(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e231b90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = retriever(\"How much are the iPhone X\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "abdac37b-b5fe-421c-826f-4fd699cb2e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Macintosh | US$29.99, it allowed adventurous Mac users to sample Apple\\'s new operating system and provide feedback for the actual release. The initial version of Mac OS X, 10.0 \"Cheetah\", was released on March 24, 2001. Older Mac OS applications could still run under early Mac OS X versions, using an environment called \"Classic\". Subsequent releases of Mac OS X included 10.1 \"Puma\" (2001), 10.2 \"Jaguar\" (2002), 10.3 \"Panther\" (2003) and 10.4 \"Tiger\" (2005). Apple discontinued the use of PowerPC microprocessors in 2006. At WWDC 2005, Steve Jobs announced this transition, revealing that Mac OS X was always developed to run on'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "passages.passages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "de70c713-1fbe-451b-b3db-24e700bc0147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pid': 48656,\n",
       "  'prob': 0.9589276606710758,\n",
       "  'rank': 1,\n",
       "  'score': 22.34375,\n",
       "  'text': 'IPhone | revenue (until the iPhone 3G), in exchange for four years of exclusive US sales, until 2011. Jobs unveiled the iPhone to the public on January 9, 2007, at the Macworld 2007 convention at the Moscone Center in San Francisco. The two initial models, a 4\\xa0GB model priced at US$499 and an 8\\xa0GB model at US$599 (both requiring a 2-year contract), went on sale in the United States on June 29, 2007, at 6:00\\xa0pm local time, while hundreds of customers lined up outside the stores nationwide. The passionate reaction to the launch of the iPhone resulted in sections of the media',\n",
       "  'long_text': 'IPhone | revenue (until the iPhone 3G), in exchange for four years of exclusive US sales, until 2011. Jobs unveiled the iPhone to the public on January 9, 2007, at the Macworld 2007 convention at the Moscone Center in San Francisco. The two initial models, a 4\\xa0GB model priced at US$499 and an 8\\xa0GB model at US$599 (both requiring a 2-year contract), went on sale in the United States on June 29, 2007, at 6:00\\xa0pm local time, while hundreds of customers lined up outside the stores nationwide. The passionate reaction to the launch of the iPhone resulted in sections of the media'},\n",
       " {'pid': 33994,\n",
       "  'prob': 0.020857021204929042,\n",
       "  'rank': 2,\n",
       "  'score': 18.515625,\n",
       "  'text': 'IPod Classic | and downloadable games. However, as of September 30, 2011, these games are no longer available on the iTunes Store. Apple introduced the first-generation iPod (M8541) on October 23, 2001, with the slogan \"1,000 songs in your pocket\". They went on sale on November 10, 2001. The first iPod had a black and white LCD (liquid-crystal display) screen and featured a 5GB hard drive capable of storing 1,000 songs encoded using MP3 and was priced at US$399. Among the iPod\\'s innovations were its small size, achieved using a 1.8\" hard drive, whereas its competitors were using 2.5\" hard drives at the',\n",
       "  'long_text': 'IPod Classic | and downloadable games. However, as of September 30, 2011, these games are no longer available on the iTunes Store. Apple introduced the first-generation iPod (M8541) on October 23, 2001, with the slogan \"1,000 songs in your pocket\". They went on sale on November 10, 2001. The first iPod had a black and white LCD (liquid-crystal display) screen and featured a 5GB hard drive capable of storing 1,000 songs encoded using MP3 and was priced at US$399. Among the iPod\\'s innovations were its small size, achieved using a 1.8\" hard drive, whereas its competitors were using 2.5\" hard drives at the'},\n",
       " {'pid': 65094,\n",
       "  'prob': 0.02021531812399507,\n",
       "  'rank': 3,\n",
       "  'score': 18.484375,\n",
       "  'text': 'Windows 8 | pre-loaded software on devices specifically developed for it. Windows 8 was distributed as a retail box product on DVD, and through a digital download that could be converted into DVD or USB install media. As part of a launch promotion, Microsoft offered \"Windows 8 Pro\" upgrades at a discounted price of US$39.99 online, or $69.99 for retail box from its launch until January 31, 2013; afterward the \"Windows 8\" price has been $119.99 and the Pro price $199.99. Those who purchased new PCs pre-loaded with Windows 7 Home Basic, Home Premium, Professional, or Ultimate between June 2, 2012 and January',\n",
       "  'long_text': 'Windows 8 | pre-loaded software on devices specifically developed for it. Windows 8 was distributed as a retail box product on DVD, and through a digital download that could be converted into DVD or USB install media. As part of a launch promotion, Microsoft offered \"Windows 8 Pro\" upgrades at a discounted price of US$39.99 online, or $69.99 for retail box from its launch until January 31, 2013; afterward the \"Windows 8\" price has been $119.99 and the Pro price $199.99. Those who purchased new PCs pre-loaded with Windows 7 Home Basic, Home Premium, Professional, or Ultimate between June 2, 2012 and January'}]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm(\"How much are the iPhone 8?\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e1f577-408c-4ede-9e27-65a24aafca5f",
   "metadata": {},
   "source": [
    "If we need passages with scores and other metadata, we can call `rm` directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37f4ff3d-de41-4fc7-8943-6dfd894dd1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pid': 30459,\n",
       "  'prob': 1.0,\n",
       "  'rank': 1,\n",
       "  'score': 22.015625,\n",
       "  'text': 'Ken Liu | Problem\" won the 2015 Hugo Award, the first translated novel in the award\\'s history to have won that honor. Ken Liu is currently writing his series \"The Dandelion Dynasty\" (edited by Joe Monti) for Saga Press. The first novel in the series, \"The Grace of Kings\", was a 2016 Nebula Award finalist. His official Star Wars novel called \"The Legends of Luke Skywalker\" was published October 31, 2017. Liu was born in 1976 in Lanzhou, China, and emigrated to the United States when he was 11 years old, initially living in Palo Alto, California, and later moving to Waterford, Connecticut.',\n",
       "  'long_text': 'Ken Liu | Problem\" won the 2015 Hugo Award, the first translated novel in the award\\'s history to have won that honor. Ken Liu is currently writing his series \"The Dandelion Dynasty\" (edited by Joe Monti) for Saga Press. The first novel in the series, \"The Grace of Kings\", was a 2016 Nebula Award finalist. His official Star Wars novel called \"The Legends of Luke Skywalker\" was published October 31, 2017. Liu was born in 1976 in Lanzhou, China, and emigrated to the United States when he was 11 years old, initially living in Palo Alto, California, and later moving to Waterford, Connecticut.'}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm(\"What is the birthplace of the first author to win a Hugo Award for a translation?\", k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2017ee-1375-4251-a24f-7f792852ffac",
   "metadata": {},
   "source": [
    "## Few-shot OpenQA with context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05c0997-e624-4fc0-824d-e13066978b0a",
   "metadata": {},
   "source": [
    "Let's build on the above core concepts to define a basic retrieval-augmented generation (RAG) program. This program solves the core task of few-shot OpenQA task and will serve as the basis for the homework questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1714dd71-02aa-4e84-840f-807b4e501732",
   "metadata": {},
   "source": [
    "We begin with a signature that takes context into account but is otherwise just like `BasicQASignature` above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bcd35bc4-9bbc-4286-ad6b-d7474b51423e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3de481d-d4dd-42c3-99c1-7a112c7f521f",
   "metadata": {},
   "source": [
    "And here is a complete program/system for the task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f84481c9-6e6a-4331-a5e1-cf2b9e27b082",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7c4c1ddd-455e-4ad5-b1b1-bf1267364660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag_model = RAG(num_passages=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7fce28fa-aa8a-4cec-a07a-5365a5eb32df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['Ken Liu | Problem\" won the 2015 Hugo Award, the first translated novel in the award\\'s history to have won that honor. Ken Liu is currently writing his series \"The Dandelion Dynasty\" (edited by Joe Monti) for Saga Press. The first novel in the series, \"The Grace of Kings\", was a 2016 Nebula Award finalist. His official Star Wars novel called \"The Legends of Luke Skywalker\" was published October 31, 2017. Liu was born in 1976 in Lanzhou, China, and emigrated to the United States when he was 11 years old, initially living in Palo Alto, California, and later moving to Waterford, Connecticut.', 'Vernor Vinge | Vernor Vinge Vernor Steffen Vinge (; born October 2, 1944) is an American science fiction author and retired professor. He taught mathematics and computer science at San Diego State University. He is the originator of the technological singularity concept and perhaps the first to present a fictional \"cyberspace\". He has won the Hugo Award for his novels and novellas \"A Fire Upon the Deep\" (1992), \"A Deepness in the Sky\" (1999), \"Rainbows End\" (2006), \"Fast Times at Fairmont High\" (2002), and \"The Cookie Monster\" (2004). Vinge published his first short story, \"Bookworm, Run!\", in the March 1966 issue of \"Analog', 'Translation | Awards annually present prizes for the best English-to-French and French-to-English literary translations. Other writers, among many who have made a name for themselves as literary translators, include Vasily Zhukovsky, Tadeusz Boy-Żeleński, Vladimir Nabokov, Jorge Luis Borges, Robert Stiller and Haruki Murakami. The first important translation in the West was that of the Septuagint, a collection of Jewish Scriptures translated into early Koine Greek in Alexandria between the 3rd and 1st centuries BCE. The dispersed Jews had forgotten their ancestral language and needed Greek versions (translations) of their Scriptures. Throughout the Middle Ages, Latin was the \"lingua franca\" of the western'],\n",
       "    answer='Lanzhou, China'\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873286e4-aaa7-4359-a5f2-04f8cbcceac8",
   "metadata": {},
   "source": [
    "An optional tiny evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "25715550-2ba8-44bb-9a11-ca3bc3e0af56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 8 / 15  (53.3): 100%|███████████████████████████████| 15/15 [00:07<00:00,  1.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_9276e th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9276e td {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_9276e_row0_col0, #T_9276e_row0_col1, #T_9276e_row0_col2, #T_9276e_row0_col3, #T_9276e_row0_col4, #T_9276e_row1_col0, #T_9276e_row1_col1, #T_9276e_row1_col2, #T_9276e_row1_col3, #T_9276e_row1_col4, #T_9276e_row2_col0, #T_9276e_row2_col1, #T_9276e_row2_col2, #T_9276e_row2_col3, #T_9276e_row2_col4, #T_9276e_row3_col0, #T_9276e_row3_col1, #T_9276e_row3_col2, #T_9276e_row3_col3, #T_9276e_row3_col4, #T_9276e_row4_col0, #T_9276e_row4_col1, #T_9276e_row4_col2, #T_9276e_row4_col3, #T_9276e_row4_col4 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "  word-wrap: break-word;\n",
       "  max-width: 400px;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_9276e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_9276e_level0_col0\" class=\"col_heading level0 col0\" >question</th>\n",
       "      <th id=\"T_9276e_level0_col1\" class=\"col_heading level0 col1\" >example_answer</th>\n",
       "      <th id=\"T_9276e_level0_col2\" class=\"col_heading level0 col2\" >context</th>\n",
       "      <th id=\"T_9276e_level0_col3\" class=\"col_heading level0 col3\" >pred_answer</th>\n",
       "      <th id=\"T_9276e_level0_col4\" class=\"col_heading level0 col4\" >answer_exact_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_9276e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_9276e_row0_col0\" class=\"data row0 col0\" >In 1517 who was Luther's bishop?</td>\n",
       "      <td id=\"T_9276e_row0_col1\" class=\"data row0 col1\" >Albert of Mainz</td>\n",
       "      <td id=\"T_9276e_row0_col2\" class=\"data row0 col2\" >['Martin Luther | St. Peter\\'s Basilica in Rome. Roman Catholic theology stated that faith alone, whether fiduciary or dogmatic, cannot justify man; justification rather depends...</td>\n",
       "      <td id=\"T_9276e_row0_col3\" class=\"data row0 col3\" >Albert of Mainz</td>\n",
       "      <td id=\"T_9276e_row0_col4\" class=\"data row0 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9276e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_9276e_row1_col0\" class=\"data row1 col0\" >When was the construction that changed the Rhine's Delta?</td>\n",
       "      <td id=\"T_9276e_row1_col1\" class=\"data row1 col1\" >20th Century</td>\n",
       "      <td id=\"T_9276e_row1_col2\" class=\"data row1 col2\" >['Rhine | characterized by the delta\\'s main arms, disconnected arms (Hollandse IJssel, Linge, Vecht, etc.) and smaller rivers and streams. Many rivers have been closed...</td>\n",
       "      <td id=\"T_9276e_row1_col3\" class=\"data row1 col3\" >second half of the 20th Century</td>\n",
       "      <td id=\"T_9276e_row1_col4\" class=\"data row1 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9276e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_9276e_row2_col0\" class=\"data row2 col0\" >How many companies were registered in Warsaw in 2006?</td>\n",
       "      <td id=\"T_9276e_row2_col1\" class=\"data row2 col1\" >304,016</td>\n",
       "      <td id=\"T_9276e_row2_col2\" class=\"data row2 col2\" >['Warsaw | a \"major world city\") by the Globalization and World Cities (GaWC) Study Group and Network from Loughborough University, placing it on a par...</td>\n",
       "      <td id=\"T_9276e_row2_col3\" class=\"data row2 col3\" >304,016</td>\n",
       "      <td id=\"T_9276e_row2_col4\" class=\"data row2 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9276e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_9276e_row3_col0\" class=\"data row3 col0\" >What is the CJEU's duty?</td>\n",
       "      <td id=\"T_9276e_row3_col1\" class=\"data row3 col1\" >to \"ensure that in the interpretation and application of the Treaties the law is observed\"</td>\n",
       "      <td id=\"T_9276e_row3_col2\" class=\"data row3 col2\" >['European Union law | judges for three years. While TEU article 19(3) says the Court of Justice is the ultimate court to interpret questions of...</td>\n",
       "      <td id=\"T_9276e_row3_col3\" class=\"data row3 col3\" >\"ensure that in the interpretation and application of the Treaties the law is observed\"</td>\n",
       "      <td id=\"T_9276e_row3_col4\" class=\"data row3 col4\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_9276e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_9276e_row4_col0\" class=\"data row4 col0\" >What would a teacher do for someone who is cocky?</td>\n",
       "      <td id=\"T_9276e_row4_col1\" class=\"data row4 col1\" >deflate</td>\n",
       "      <td id=\"T_9276e_row4_col2\" class=\"data row4 col2\" >['Teacher | described the place of a teacher in learning as follows: \"The real bulk of learning takes place in self-study and problem solving with...</td>\n",
       "      <td id=\"T_9276e_row4_col3\" class=\"data row4 col3\" >deflate</td>\n",
       "      <td id=\"T_9276e_row4_col4\" class=\"data row4 col4\" >✔️ [True]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x330461850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                <div style='\n",
       "                    text-align: center;\n",
       "                    font-size: 16px;\n",
       "                    font-weight: bold;\n",
       "                    color: #555;\n",
       "                    margin: 10px 0;'>\n",
       "                    ... 10 more rows not displayed ...\n",
       "                </div>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "53.33"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiny_evaluater(rag_model, metric=answer_exact_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb28556-d901-4b6b-8a7d-93040203294d",
   "metadata": {},
   "source": [
    "## Question 1: Optimizing RAG [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f481081-3e16-4ccd-b379-c7e0c3011286",
   "metadata": {},
   "source": [
    "We used `RAG` above as a zero-shot system. We could turn it into a few-shot system by using `LabeledFewShot` as we did in [the teleprompting section](#Teleprompting) above, but this may actually be problematic: if we randomly sample demonstrations with retrieved passages, we might be instructing the model with a lot of cases where the context passage isn't helping (and may actually be actively misleading the model). \n",
    "\n",
    "What we'd like to do is select demonstrations where the model gets the answer correct and the context passage does contain the answer. To do this, we will use the DSPy `BootstrapFewShot` optimizer. There are two steps for this: (1) defining a metric and (2) running the optimizer.\n",
    "\n",
    "__Note__: The code for this question can be found in the DSPy tutorials, and you should feel free to make use of that code. The goal is to help you understand the design patterns and overall logic of optimizing DSPy programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0ae027-f51a-4607-822f-2a721acde73c",
   "metadata": {},
   "source": [
    "__Task 1__: Complete `validate_context_and_answer` according to the specification in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ad09f428-1a68-4cef-9e7a-7c6faf9244a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate_context_and_answer(example, pred, trace=None):\n",
    "    \"\"\"Return True if `example.answer` matches `pred.answer` according\n",
    "    to `dspy.evaluate.answer_exact_match` and `pred.context` contains\n",
    "    `example.answer` according to `dspy.evaluate.answer_passage_match`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    example: dspy.Example \n",
    "        with attributes `answer` and `context`\n",
    "    pred: dspy.Example \n",
    "        with attributes `answer` and `context`\n",
    "    trace : None (included for dspy internal compatibility)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "    ##### YOUR CODE HERE\n",
    "    from dspy.evaluate import answer_exact_match, answer_passage_match\n",
    "    answer_match = answer_exact_match(example, pred)   \n",
    "    context_match = answer_passage_match(example, pred)\n",
    "    \n",
    "    return answer_match and context_match\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0918c5f-2864-4856-adcf-ccb94aca6108",
   "metadata": {},
   "source": [
    "A test you can use to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddbca59c-7c11-4e4b-bec3-18a2ecde563b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_validate_context_and_answer(func):\n",
    "    examples = [\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"B\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"B\"),\n",
    "            True\n",
    "        ),\n",
    "        # Context doesn't contain answer, but predicted answer is correct.\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"D\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
    "            False\n",
    "        ),\n",
    "        # Context contains answer, but predicted answer is not correct.\n",
    "        (\n",
    "            dspy.Example(question=\"Q1\", answer=\"C\"),\n",
    "            dspy.Prediction(question=\"Q1\", context=\"A B C\", answer=\"D\"),\n",
    "            False\n",
    "        )\n",
    "    ]\n",
    "    errcount = 0\n",
    "    for ex, pred, result in examples:\n",
    "        predicted = func(ex, pred, trace=None)\n",
    "        if predicted != result:\n",
    "            errcount += 1\n",
    "            print(f\"Error for `{func.__name__}`: \"\n",
    "                  f\"Expected inputs\\n\\t{ex}\\n\\t{pred} to return {result}.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38aa3141-ae8f-4bc6-a26e-64d108537612",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `validate_context_and_answer`\n"
     ]
    }
   ],
   "source": [
    "test_validate_context_and_answer(validate_context_and_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f091ca79-ccbe-4429-bfe7-c4f1de118adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "__Task 2__: Complete `bootstrap_optimize` according to the specification in the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "129e7e92-033e-4f38-b309-94dac2b66d87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dspy.teleprompt import BootstrapFewShot\n",
    "\n",
    "def bootstrap_optimize(model):\n",
    "    \"\"\"Use `BootstrapFewShot` to optimize `model`, with the metric set\n",
    "    to `validate_context_and_answer` as defined above and default\n",
    "    values for all other keyword arguments to `BootstrapFewShot`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: dspy.Module\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dspy.Module, the optimized version of `model`\n",
    "\n",
    "    \"\"\"\n",
    "    pass\n",
    "    ##### YOUR CODE HERE\n",
    "    optimizer = BootstrapFewShot(metric=validate_context_and_answer)\n",
    "    optimized_model = optimizer.compile(model, trainset=dev_exs[: 15])\n",
    "    \n",
    "    return optimized_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f26af22-6d7d-4456-9e30-8f80f5b0b401",
   "metadata": {},
   "source": [
    "A test you can use to check your implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "30dd9f56-31cc-4e45-8bc2-0fe56c3806a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_bootstrap_optimize(func):\n",
    "    model = RAG()\n",
    "    compiled = func(model)\n",
    "    if not hasattr(compiled, \"_compiled\") or not compiled._compiled:\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "               \"The return value is not a compiled program.\")\n",
    "        return None\n",
    "    state = compiled.dump_state()\n",
    "    if not state['generate_answer']['demos']:\n",
    "        print(f\"Error for `{func.__name__}`: \"\n",
    "               \"The compiled program has no `demos`.\")\n",
    "        return None\n",
    "    print(f\"No errors detected for `{func.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "733c1c31-9c68-4d2a-a1c3-4eed0e1caa6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████▏                                     | 6/15 [00:00<00:00, 625.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 4 full traces after 7 examples in round 0.\n",
      "[('retrieve', <dspy.retrieve.retrieve.Retrieve object at 0x3306573d0>), ('generate_answer', Predict(ContextQASignature(context, question -> answer\n",
      "    instructions='Answer questions with short factoid answers.'\n",
      "    context = Field(annotation=str required=True json_schema_extra={'desc': 'may contain relevant facts', '__dspy_field_type': 'input', 'prefix': 'Context:'})\n",
      "    question = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Question:', 'desc': '${question}'})\n",
      "    answer = Field(annotation=str required=True json_schema_extra={'desc': 'often between 1 and 5 words', '__dspy_field_type': 'output', 'prefix': 'Answer:'})\n",
      ")))]\n",
      "No errors detected for `bootstrap_optimize`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_bootstrap_optimize(bootstrap_optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9971ffd0-a563-4d56-a896-0735a63ae92f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question 2: Multi-passage summarization [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527e4d85-05d7-4bc2-beaf-2434d4fe41da",
   "metadata": {},
   "source": [
    "The `dspy.Retrieve` layer in our `RAG` retrieves `k` passages, where `k` is under the control of the user. One hypothesis one might have is that it would be good to summarize these passages before using them as evidence. This seems especially likely to help in scenarios where the question can be answered only by synthesizing information across documents – it might be too much to ask the language model to do both synthesizing and answering in a single step.\n",
    "\n",
    "The current question maps out a basic strategy for summarization. The heart of it is a new signature called `SummarizeSignature`. This can be used on its own with a simple `dspy.Predict` call, and we'll incorporate it into a RAG program in the next question.\n",
    "\n",
    "For this question, though, your task is just to complete `SummarizeSignature`. The requirements are as follows:\n",
    "\n",
    "1. A `__doc__` value that gives an instruction that seems to work well. You can decide what to say here.\n",
    "2. A `dspy.InputField` named `context`. You can decide whether to use the `desc` parameter.\n",
    "3. A `dspy.OutputField` named `summary`. You can decide whether to use the `desc` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "b7c080a6-d2e1-4d7a-ac60-5ef3a6931ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummarizeSignature(dspy.Signature):\n",
    "    pass\n",
    "    ##### YOUR CODE HERE\n",
    "    __doc__ = \"\"\"Summarize the key information of the provided context into 4-5 sentences\"\"\"\n",
    "\n",
    "    context = dspy.InputField()\n",
    "    summary = dspy.OutputField()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6091f20-1cae-4e04-bd50-929271ae6a18",
   "metadata": {},
   "source": [
    "Here's a simple test that just checks for the required pieces in a basic way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "428c971a-2dcd-4344-afa0-8e52938ca4ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_SummarizeSignature(sigclass):\n",
    "    fields = sigclass.fields\n",
    "    expected_fieldnames = ['context', 'summary']\n",
    "    fieldnames = sorted(fields)\n",
    "    errcount = 0\n",
    "    if expected_fieldnames != fieldnames:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{sigclass.__name__}`: \"\n",
    "              f\"Expected fieldnames {expected_fieldnames}, got {fieldnames}.\")\n",
    "    if not sigclass.__doc__:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{sigclass.__name__}`: No docstring specified.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{sigclass.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fec39e4d-b3ca-4355-9695-c9f61a24f3d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `SummarizeSignature`\n"
     ]
    }
   ],
   "source": [
    "test_SummarizeSignature(SummarizeSignature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ee5d0-2bd6-4cb0-873c-21f963a78555",
   "metadata": {},
   "source": [
    "Here is the simplest way to use `SummarizeSignature`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5e8129a3-90fb-4810-b18b-84e75525dd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizer = dspy.Predict(SummarizeSignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d8bfdb34-07d8-4488-a1ed-1b4788a2a119",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context discusses the presence of indigenous languages in Latin America, with languages like Quichua, Aymara, Quechua, Guaraní, and Guarani being recognized and even holding official status in countries like Ecuador, Bolivia, Paraguay, and Argentina. Additionally, the text mentions the presence of other languages in Argentina, such as Standard German, Yiddish, Catalan, Mapudungun, and Chinese. It also highlights the diversity of indigenous languages spoken in the Americas, with over a thousand different languages being spoken, including Quechuan languages, Aymara, Guaraní, Mayan languages, and Nahuatl. Despite the influence of Western culture, many indigenous peoples still maintain traditional aspects of their culture while adapting'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(context=retriever(\"Where is Guarani spoken?\").passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1503fc95-df36-4274-9986-ef3ca991e6b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Summarize the key information of the provided context into 4-5 sentences\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: ${context}\n",
      "Summary: ${summary}\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «Latin Americans | alongside Spanish and any other indigenous language in the areas where they predominate. In Ecuador, while holding no official status, the closely related Quichua is a recognized language of the indigenous people under the country's constitution; however, it is only spoken by a few groups in the country's highlands. In Bolivia, Aymara, Quechua and Guaraní hold official status alongside Spanish. Guarani is, along with Spanish, an official language of Paraguay, and is spoken by a majority of the population (who are, for the most part, bilingual), and it is co-official with Spanish in the Argentine province of Corrientes. In Nicaragua,»\n",
      "[2] «Languages of Argentina | is classified as a Quechua II language and is referred to as Quechua IIC by linguists. Standard German is spoken by between 400,000 and 500,000 Argentines of German ancestry, though it has also been stated that there could be as many as 1,800,000. There are around 200,000 Yiddish speakers in Argentina. Guaraní is spoken by 200,000 people, mostly in Corrientes (where it is official \"de jure\") and Misiones. There are 174,000 speakers of the Catalan language. Mapudungun is spoken by 100,000 Mapuche people in the provinces of Neuquén, Río Negro, Chubut, Buenos Aires, and La Pampa. Chinese is spoken by»\n",
      "[3] «Indigenous peoples of the Americas | Bolivia, Chile, Ecuador, Greenland, Guatemala, Mexico, and Peru. At least a thousand different indigenous languages are spoken in the Americas. Some, such as the Quechuan languages, Aymara, Guaraní, Mayan languages, and Nahuatl, count their speakers in millions. Many also maintain aspects of indigenous cultural practices to varying degrees, including religion, social organization, and subsistence practices. Like most cultures, over time, cultures specific to many indigenous peoples have evolved to incorporate traditional aspects, but also cater to modern needs. Some indigenous peoples still live in relative isolation from Western culture and a few are still counted as uncontacted peoples. The specifics»\n",
      "Summary:\u001b[32m The context discusses the presence of indigenous languages in Latin America, with languages like Quichua, Aymara, Quechua, Guaraní, and Guarani being recognized and even holding official status in countries like Ecuador, Bolivia, Paraguay, and Argentina. Additionally, the text mentions the presence of other languages in Argentina, such as Standard German, Yiddish, Catalan, Mapudungun, and Chinese. It also highlights the diversity of indigenous languages spoken in the Americas, with over a thousand different languages being spoken, including Quechuan languages, Aymara, Guaraní, Mayan languages, and Nahuatl. Despite the influence of Western culture, many indigenous peoples still maintain traditional aspects of their culture while adapting\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7a44f-c50d-4674-9fbb-fcf216222e3a",
   "metadata": {},
   "source": [
    "## Question 3: Summarizing RAG [2 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c812e189-2778-442f-81b1-577c303445a8",
   "metadata": {},
   "source": [
    "Your task for this question is to modify `RAG` as defined above so that the retrieved passages are summarized before being passed to `generate_answer`. \n",
    "\n",
    "Here is the `RAG` system copied from above with the class name changed to the one we will use for this new system. Your task is to add the summarization step. This should be very straightforward given the modular design that DSPy supports and encourages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fa956847-d6ff-40cf-bf02-9043863e548e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SummarizingRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=3):\n",
    "        # Please name your summarization later `summarize` so that we\n",
    "        # can check for its presence.\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        ##### YOUR CODE HERE\n",
    "        self.summarize = dspy.Predict(SummarizeSignature)\n",
    "\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        ##### YOUR CODE HERE\n",
    "        context = [self.summarize(context=c).summary for c in context]\n",
    "\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16b65d8-14ca-4dbe-a815-a0d00940b0b4",
   "metadata": {},
   "source": [
    "A simple test for this design spec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "824f063d-1735-4bf3-9337-e9728a5b7800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_SummarizingRAG(classname):\n",
    "    model = classname(num_passages=3)\n",
    "    errcount = 0\n",
    "    if not hasattr(model, \"summarize\"):\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{classname.__name__}`: \"\n",
    "              f\"Expected a layer called 'summarize'\")\n",
    "    context = model.retrieve(\"What are some foods?\").passages\n",
    "    pred = model(\"What are some foods?\")\n",
    "    if context == pred.context:\n",
    "        errcount += 1\n",
    "        print(f\"Error for `{classname.__name__}`: \"\n",
    "              \"The model seems to be using raw retrieved contexts \"\n",
    "              \"for predictions rather than summarizing them.\")\n",
    "    if errcount == 0:\n",
    "        print(f\"No errors detected for `{classname.__name__}`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8e1d38c4-540c-4473-b464-0061b5b8a09c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors detected for `SummarizingRAG`\n"
     ]
    }
   ],
   "source": [
    "test_SummarizingRAG(SummarizingRAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3b6ad-b960-4b8f-8137-a9b90953b2fc",
   "metadata": {},
   "source": [
    "Model usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "95e03778-5a7f-4119-ac62-f4965bfe9a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summarizing_rag_model = SummarizingRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "5077370b-156f-4738-948b-86d832b2ebbd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['Ken Liu, a Chinese-American author, made history by winning the 2015 Hugo Award for his novel \"The Three-Body Problem,\" the first translated work to do so. He is known for his series \"The Dandelion Dynasty,\" with the first book, \"The Grace of Kings,\" being a Nebula Award finalist. Liu also wrote an official Star Wars novel titled \"The Legends of Luke Skywalker.\" Born in 1976 in China, Liu immigrated to the United States at the age of 11, settling in California and later Connecticut.', 'Vernor Vinge is an American science fiction author and former professor known for his work on the technological singularity concept and cyberspace. He has won the Hugo Award for several of his novels and novellas, including \"A Fire Upon the Deep\" and \"Rainbows End\". Vinge began his writing career with the publication of his short story \"Bookworm, Run!\" in 1966. He taught mathematics and computer science at San Diego State University.', 'Context: Translation | Awards annually present prizes for the best English-to-French and French-to-English literary translations. Other notable literary translators include Vasily Zhukovsky, Tadeusz Boy-Żeleński, Vladimir Nabokov, Jorge Luis Borges, Robert Stiller, and Haruki Murakami. The first significant translation in the West was the Septuagint, a collection of Jewish Scriptures translated into early Koine Greek in Alexandria between the 3rd and 1st centuries BCE. Latin was the dominant language in the western world during the Middle Ages.'],\n",
       "    answer='China'\n",
       ")"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizing_rag_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e5c693f2-86f9-4cdb-986f-5584c49a8fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Answer questions with short factoid answers from given context, only use your own knowledge when answer cannot be found in the context.\n",
      "\n",
      "---\n",
      "\n",
      "Follow the following format.\n",
      "\n",
      "Context: may contain relevant facts\n",
      "\n",
      "Question: ${question}\n",
      "\n",
      "Reasoning: Let's think step by step in order to ${produce the answer}. We ...\n",
      "\n",
      "Answer: often between 1 and 5 words\n",
      "\n",
      "---\n",
      "\n",
      "Context:\n",
      "[1] «ozone depletion, gradual thinning of Earth’s ozone layer in the upper atmosphere caused by the release of chemical compounds containing gaseous chlorine or bromine from industry and other human activities. The thinning is most pronounced in the polar regions, especially over Antarctica.»\n",
      "[2] «Ozone depletion is a major environmental problem because it increases the amount of ultraviolet (UV) radiation that reaches Earth’s surface, which increases the rate of skin cancer, eye cataracts, and genetic and immune system damage. The Montreal Protocol, ratified in 1987, was the first of several comprehensive international agreements enacted to halt the production and use of ozone-depleting chemicals.»\n",
      "[3] «Ozone layer depletion is the thinning of the ozone layer present in the upper atmosphere. This happens when the chlorine and bromine atoms in the atmosphere come in contact with ozone and destroy the ozone molecules. One chlorine can destroy 100,000 molecules of ozone.»\n",
      "[4] «Ozone depletion | Ozone depletion Ozone depletion describes two related events observed since the late 1970s: a steady lowering of about four percent in the total amount of ozone in Earth's atmosphere (the ozone layer), and a much larger springtime decrease in stratospheric ozone around Earth's polar regions. The latter phenomenon is referred to as the ozone hole. There are also springtime polar tropospheric ozone depletion events in addition to these stratospheric events. The main cause of ozone depletion and the ozone hole is manufactured chemicals, especially manufactured halocarbon refrigerants, solvents, propellants and foam-blowing agents (chlorofluorocarbons (CFCs), HCFCs, halons), referred to as ozone-depleting»\n",
      "[5] «Ozone depletion consists of two related events observed since the late 1970s: a steady lowering of about four percent in the total amount of ozone in Earth's atmosphere, and a much larger springtime decrease in stratospheric ozone (the ozone layer) around Earth's polar regions. The latter phenomenon is referred to as the ozone hole.»\n",
      "[6] «Ozone depletion | as the International Day for the Preservation of the Ozone Layer, or \"World Ozone Day\", to commemorate the signing of the Montreal Protocol on that date in 1987. Ozone depletion Ozone depletion describes two related events observed since the late 1970s: a steady lowering of about four percent in the total amount of ozone in Earth's atmosphere (the ozone layer), and a much larger springtime decrease in stratospheric ozone around Earth's polar regions. The latter phenomenon is referred to as the ozone hole. There are also springtime polar tropospheric ozone depletion events in addition to these stratospheric events. The main»\n",
      "[7] «Ozone depleting potential is a measure of how much damage a chemical can cause to the ozone layer compared with a similar mass of trichlorofluoromethane (CFC-11). CFC-11, with an ozone depleting potential of 1.0, is used as the base figure for measuring ozone depleting potential.»\n",
      "[8] «Ozone depletion | CFCs means that nitrous oxide (), which is not covered by the Montreal Protocol, has become the most highly emitted ozone-depleting substance and is expected to remain so throughout the 21st century. A 2005 IPCC review of ozone observations and model calculations concluded that the global amount of ozone has now approximately stabilized. Although considerable variability is expected from year to year, including in polar regions where depletion is largest, the ozone layer is expected to begin to recover in coming decades due to declining ozone-depleting substance concentrations, assuming full compliance with the Montreal Protocol. The Antarctic ozone hole is»\n",
      "[9] «Ozone depletion | substances (ODS). These compounds are transported into the stratosphere by the winds after being emitted from the surface. Once in the stratosphere, they release halogen atoms through photodissociation, which catalyze the breakdown of ozone (O) into oxygen (O). Both types of ozone depletion were observed to increase as emissions of halocarbons increased. Ozone depletion and the ozone hole have generated worldwide concern over increased cancer risks and other negative effects. The ozone layer prevents most harmful UVB wavelengths of ultraviolet light (UV light) from passing through the Earth's atmosphere. These wavelengths cause skin cancer, sunburn and cataracts, which were projected»\n",
      "[10] «Solar radiation management | chaotic in nature. Ozone depletion is a risk of techniques involving sulfur delivery into the stratosphere. Not all side effects are negative, and an increase in agricultural productivity has been predicted by some studies due to the combination of more diffuse light and elevated carbon dioxide concentration. If solar radiation management were masking a significant amount of warming and then were to abruptly stop, the climate would rapidly warm. This would cause a sudden rise in global temperatures towards levels which would have existed without the use of the climate engineering technique. The rapid rise in temperature may lead to»\n",
      "\n",
      "Question: what is ozone depletion?\n",
      "\n",
      "Reasoning: Let's think step by step in order to\u001b[32m define the term \"ozone depletion\" based on the context provided.\n",
      "\n",
      "Answer: gradual thinning of Earth's ozone layer\u001b[0m\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ebc3e9-7baf-4e1c-81a0-8c1e3588a882",
   "metadata": {},
   "source": [
    "Note: if you decide to use `BootstrapFewShot` on this, be sure not to use the metric we defined above, which requires that the passage embeds the correct answer as a substring. Now that we are summarizing, this is unlikely to hold, even if the answers are good ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19655d70-007c-4a41-9f3b-e20df9c5169b",
   "metadata": {},
   "source": [
    "## Question 4: Your original system [3 points]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8d268f-70e1-4325-a2ff-7361d73788b9",
   "metadata": {},
   "source": [
    "This question asks you to design your own few-shot OpenQA system. All of the code above can be used and modified for this, and the requirement is just that you try something new that goes beyond what we've done so far. \n",
    "\n",
    "Terms for the bake-off:\n",
    "\n",
    "* You can make free use of SQuAD and other publicly available data.\n",
    "\n",
    "* The LM must be an autoregressive language model. No trained QA components can be used. This includes general purpose LMs that have been fine-tuned for QA. (We have obviously waded into some vague territory here. The spirit of this is to make use of frozen, general-purpose models. We welcome questions about exactly how this is defined, since it could be instructive to explore this.)\n",
    "\n",
    "Here are some ideas for the original system:\n",
    "\n",
    "* We have relied almost entirely on `dspy.Predict`. Drop-in replacements include `dspy.ChainOfThought` and `dspy.ReAct`.\n",
    "\n",
    "* We have used only one retriever. DSPy supports other retrieval mechanisms, including retrieval using [You.com](https://you.com/).\n",
    "\n",
    "* DSPy includes additional optimizers. Two that are worth trying are `SignatureOptimizer` for automatic prompt exploration and `BootstrapFewShotWithRandomSearch`, which combines `LabeledFewShot` and `BootstrapFewShot`,\n",
    "\n",
    "* Our one-step summarization procedure from Question 3 doesn't change the query to the retriever. We might want it to change as we gather evidence. This is a common design principle for multi-hop OpenQA systems.\n",
    "\n",
    "__Original system instructions__:\n",
    "\n",
    "In the cell below, please provide a brief technical description of your original system, so that the teaching team can gain an understanding of what it does. This will help us to understand your code and analyze all the submissions to identify patterns and strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b557f3c3-ee72-480e-9d99-9095372f99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE MAKE SURE TO INCLUDE THE FOLLOWING BETWEEN THE START AND STOP COMMENTS:\n",
    "#   1) Textual description of your system.\n",
    "#   2) The code for your original system.\n",
    "# PLEASE MAKE SURE NOT TO DELETE OR EDIT THE START AND STOP COMMENTS\n",
    "\n",
    "# START COMMENT: Enter your system description in this cell.\n",
    "\n",
    "\"\"\"\n",
    "Textual description of your system:\n",
    "\n",
    "The idea is to combine the information retrieval of ColBERT and You.com get a larger number of candidates (20 results from each in this case), \n",
    "and use a cross encoder reranker to pick 10 most relevant passages from the 40, and then pass to the QA module.\n",
    "The QA module also has some minor improvement, I updated the prompt a little bit and also using the ChainOfThought module so that the LLM \n",
    "will reasoning before answering.\n",
    "Overall after some experiment, I found the ColBERT mostly return more relevant passage than the you.com, including results from \n",
    "you.com's search API to cover some knowledge gap for ColBERT server.\n",
    "\"\"\"\n",
    "\n",
    "from dspy.retrieve.you_rm import YouRM\n",
    "from sentence_transformers import CrossEncoder\n",
    "import os\n",
    "\n",
    "class EnhancedQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers from given context, only use your own knowledge when answer cannot be found in the context.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "    \n",
    "class EnhancedRAG(dspy.Module):\n",
    "    def __init__(self, num_passages=10, colbert_cnt=20, you_cnt=20):\n",
    "        super().__init__()\n",
    "        self.num_passages = num_passages\n",
    "        self.colbert_cnt = colbert_cnt\n",
    "        self.you_cnt = you_cnt\n",
    "        self.colbert_retrieve = dspy.ColBERTv2(url=\"http://10.0.0.38:8889//api/search\")\n",
    "        self.you_retrieve = YouRM(endpoint=\"search\", safesearch=\"strict\")\n",
    "        self.reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "        self.generate_answer = dspy.ChainOfThought(EnhancedQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        colbert_results = [r['long_text'] for r in self.colbert_retrieve(question, k=self.colbert_cnt)]\n",
    "        you_results = [r['long_text'] for r in self.you_retrieve(question, k=self.you_cnt)]\n",
    "        reranked_context = [r['text'] for r in self.reranker.rank(question, colbert_results + you_results, return_documents=True)][:self.num_passages]\n",
    "        prediction = self.generate_answer(context=reranked_context, question=question)\n",
    "        return dspy.Prediction(context=reranked_context, answer=prediction.answer)\n",
    "\n",
    "enhanced_rag = EnhancedRAG()\n",
    "# STOP COMMENT: Please do not remove this comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "274a8684-02bb-4948-9837-35fde57b8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_rag = EnhancedRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a94302bd-ec50-4fb6-9db3-415072649ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=['The iPhone 16 in White, a new color. Apple/Business Insider ... The iPhone 16 Pro and iPhone 16 Pro Max are available in four colors: Desert Titanium, Natural Titanium, Black Titanium, and White Titanium. Their titanium frames and rear glass panels have a frosted matte texture.', \"The iPhone 16 also comes with a new color-infused backglass that has allowed Apple to get some gorgeous, saturated, and rich colors like Ultramarine, Teal, and Pink. On the other hand, the iPhone 16 Pro and Pro Max continue Apple's tradition of a more conservative color approach for the pro-oriented people.\", 'Black color is almost identical on the iPhone 16 and iPhone 15 | Image Credit - Apple ... The iPhone 16 Pro and Pro Max maintain a professional and sleek aesthetic, with subtle and refined color options. The Pro models this year continue to follow the Titanium-inspired theme, but this time, they feature a grade 5 titanium.', 'For the Black Titanium version, the camera island and frame are a deeper black than the rear glass panel. The iPhone 16 Pro in Black Titanium, a previously existing color option. Apple/Business Insider ... The White Titanium option for the iPhone 16 Pro models is the most uniform in color (the Pro Max model pictured).', 'As with the standard models, the Pro models are also available in the same shades as each other, but the selection differs from that of the iPhone 16 and iPhone 16 Plus, as you can see below. ... One shade you can get the iPhone 16 Pro and iPhone 16 Pro Max in is Black Titanium, and this is a very familiar shade, as it unsurprisingly looks like the iPhone 15 Pro in Black Titanium.', \"With a matte finish on their back glass, and titanium side rails, the iPhone 16 Pro and iPhone 16 Pro Max follow in the footsteps of the iPhone 15 Pro models last year. They also kept three of the four colors Apple sold the older Pros in, swapping out just one. Get instant access to breaking news, the hottest reviews, great deals and helpful tips. A Natural Titanium iPhone 16 Pro (Image credit: Tom's Guide) Your options for a Pro iPhone this year are Desert Titanium, Natural Titanium, White Titanium and Black Titanium.\", 'This is basically just a shade of white, which itself is a very popular, common, and (whisper it) ordinary smartphone color. So this is likely to sell well and unlikely to turn heads, but fitting in is sometimes desirable. ... Finally, there’s a Black Titanium shade, which has a hint of gray to it but is by far the darkest shade that you can get the iPhone 16 Pro and iPhone 16 Pro Max in.', \"The standout color for the Pro models this year is a beige option, officially called 'Desert Titanium,' bringing a fresh touch of sophistication to the muted color palette. ... The standard iPhone 16 models offer a variety of shades, from classic hues to some very vibrant options, so you can choose the one that best fits your preferences and style. ... A not-so-subtle pink variant is officially part of the lineup, providing a charming yet daring look for those who love a touch of elegance while still conserving the bold look we're seeing from the new color palette.\", 'Next, we have a gray shade, which is sold as Natural Titanium, and this is a color that you could also get the iPhone 15 Pro and Pro Max in. Aside from the fact that it was used last year this is quite an unusual color for a phone, but it’s a smart, understated shade in line with the colors Apple tends to choose for its Pro phones. ... Now we’re coming to the more conventional colors, with White Titanium being next up. This again is a color that you can get the iPhone 15 Pro line in as well as the iPhone 16 Pro line, so it should be a familiar shade.', \"A Desert Titanium iPhone 16 Pro Max. (Image credit: Tom's Guide) While on their face three of the colors do appear to be the same as the iPhone 15 Pro's options, the iPhone 16 Pro versions of the three existing colors seem to have a slightly shinier finish to them, despite still having a matte texture.\"],\n",
       "    answer='Desert Titanium, Natural Titanium, Black Titanium, White Titanium'\n",
       ")"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_rag('what are the colors for iPhone 16 Pro Max?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "ef655a9e-37f6-429b-9884-ff90016f8b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    context=[\"Refund on Apple iPhone 15 and iPhone 14: What Apple's 'price protection' policy says and the conditions that apply ... Apple has unveiled its new iPhone 16 series featuring four models: iPhone 16, iPhone 16 Plus, iPhone 16 Pro, and iPhone 16 Pro Max. Pre-orders commence on September 13 with sales starting on September 20.\", 'Returning after 14 days Can I return my sealed iPhone 12 Pro Max after 14 days 2177 2 ... According to Apples Returns and Refunds policy below the iPhone will likely have been required to be returned within 14 calendar days.', 'I purchased the iphone 16 plus a few days back, is it possible to go to the apple store and switch/upgrade to the pro max? ... Click here to read about Apple Store Returns & Refunds--> Returns & Refunds - Shopping Help - Apple - For the USA \"You have 14 calendar days to return an item from the date you received it.\"', \"Some people are returning because they think there are flaws in the 16 Pro though. So far there's screen too big, bezel too small, camera control finicky, screen brightness issues, screen sensitivity issues, etc. Some are manufacturing defects, some are preferences in design.\", 'Seeking validation, attention and justification for their decisions to get the latest iPhone to \"impress\" others. I\\'m sure 99% of average people who don\\'t frequent these forums don\\'t give a you know what whether you returned the Desert Titanium 1 TB 16 Pro Max or not.', \"I bought yesterday an iPhone 16 pro at the apple store but I made the mistake of not seeing that I chose the 128gb version, I opened the box and that's when I noticed I bought the wrong version, is there any chance to return the phone or get the 256 version plus the difference I need to pay?\", 'I returned mine and got an iPhone 16 instead. Click to expand... I was checking out the 16s when in store. I could really go for a 16 plus. Love the vibrant colors. ... Nope. I love mine 🤷🏻\\u200d♀️ ... Click to expand... I had a 15 pro but have to return it to my company.', 'Please note that returning your iPhone pursuant to this policy will not automatically cancel your mobile network agreement. You must contact your mobile network operator to cancel your mobile network service. If you cancel your mobile network service, you will be responsible for all applicable usage fees, prorated access charges, taxes, surcharges, or other charges imposed by your mobile network operator through the termination date, including any early termination fees or penalties, if applicable.', 'Click to expand... The EU will likely say it’s anticompetitive that Apple has a no hassle return policy as it makes folks more likely to try out and potentially keep an iPhone. As a result, they’ll force them to have a more onerous process. Hope that’s something they keep in the EU.', 'Whether you return online or in person, it is also important to note that a fee will usually be applied even if the box is still closed and sealed. Knowing the return policies of a product is a good idea no matter the device, and iPhones are no different.'],\n",
       "    answer='14 calendar days'\n",
       ")"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_rag(\"what's the return policy for iPhone 16 Pro?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b39c60-7494-46a6-b450-42b7e9fe3aad",
   "metadata": {},
   "source": [
    "## Question 5: Bakeoff entry [1 point]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff871c1-cc38-4e2f-af38-45b3619e8329",
   "metadata": {},
   "source": [
    "For the bake-off, you simply need to be able to run your system on the file \n",
    "\n",
    "```data/openqa/cs224u-openqa-test-unlabeled.txt```\n",
    "\n",
    "The following code should download it for you if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "4ca87f81-556b-46eb-904f-a3df70fdacb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [..............................................................................] 16822 / 16822"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "\n",
    "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")):\n",
    "    os.makedirs(os.path.join('data', 'openqa'), exist_ok=True)\n",
    "    wget.download('https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt', out='data/openqa/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0024b-9af7-4e3b-930e-1e7603d4d85c",
   "metadata": {},
   "source": [
    "If the above fails, you can just download https://web.stanford.edu/class/cs224u/data/cs224u-openqa-test-unlabeled.txt and place it in `data/openqa`.\n",
    "\n",
    "This file contains only questions. The starter code below will help you structure this. It writes a file \"cs224u-openqa-bakeoff-entry.json\" to the current directory. That file should be uploaded as-is. Please do not change its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "403b0000-5bc0-4657-91e4-5a6e87f2f899",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tqdm\n",
    "\n",
    "def create_bakeoff_submission(model):\n",
    "    \"\"\"\"\n",
    "    The argument `model` is a `dspy.Module`. The return value of its\n",
    "    `forward` method must have an `answer` attribute.\n",
    "    \"\"\"\n",
    "\n",
    "    filename = os.path.join(\"data\", \"openqa\", \"cs224u-openqa-test-unlabeled.txt\")\n",
    "\n",
    "    # This should become a mapping from questions (str) to response\n",
    "    # dicts from your system.\n",
    "    gens = {}\n",
    "\n",
    "    with open(filename) as f:\n",
    "        questions = f.read().splitlines()\n",
    "\n",
    "    # Here we loop over the questions, run the system `model`, and\n",
    "    # store its `answer` value as the prediction:\n",
    "    for question in tqdm.tqdm(questions):\n",
    "        gens[question] = model(question=question).answer\n",
    "\n",
    "    # Quick tests we advise you to run:\n",
    "    # 1. Make sure `gens` is a dict with the questions as the keys:\n",
    "    assert all(question in gens for q in questions)\n",
    "    # 2. Make sure the values are str:\n",
    "    assert all(isinstance(d, str) for d in gens.values())\n",
    "\n",
    "    # And finally the output file:\n",
    "    with open(\"cs224u-openqa-bakeoff-entry.json\", \"wt\") as f:\n",
    "        json.dump(gens, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0f32a8-547e-4a2c-8283-44adf69657ed",
   "metadata": {},
   "source": [
    "Here's what it looks like to evaluate our first program, `basic_qa_model`, on the bakeoff data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "ce20e9ae-bb82-4dff-896f-aad7f150177d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 400/400 [11:06<00:00,  1.67s/it]\n"
     ]
    }
   ],
   "source": [
    "create_bakeoff_submission(enhanced_rag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80679b58-4d87-49da-9df9-c1f92fe27ae3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
